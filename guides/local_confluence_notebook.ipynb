{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess as sp\n",
    "mnt_dir = '/nas/cee-water/cjgleason/travis/data/confluence_runs/osu_testing/mnt'\n",
    "sif_dir = '/nas/cee-water/cjgleason/travis/repos/singularity_sifs'\n",
    "partition = 'cpu-preempt'\n",
    "singularity_version = '3.7.0'\n",
    "report_dir = '/nas/cee-water/cjgleason/travis/repos/confluence-local/Report'\n",
    "\n",
    "command_dict = {\n",
    "    'ssc':'singularity run --bind /nas/cee-water/cjgleason/travis/data/ssc/:/mnt/data, /home/tsimmons_umass_edu/:/root/ ssc_pre.sif -i ${SLURM_ARRAY_TASK_ID}',\n",
    "    'datagen':'singularity run --bind ' + f'{mnt_dir}/input:/data --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'datagen.sif')+' -c river -i -235 -p POCLOUD -s SWOT_L2_HR_RiverSP_1.1 -t 2023-01-01T00:00:00Z,2023-10-05T23:59:59Z -d /data -k 1b5b3fc2-b1b5-4495-b6ea-f05ae0b09519 -w /data/sword_patches_v215.json -j /data/continent.json -u /data/reaches_of_interest.json --hpc',\n",
    "    'input': 'singularity run --bind ' + f'{mnt_dir}/input:/mnt/data --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'input.sif')+' -i -235 -r /mnt/data/reach_node.json -p /mnt/data/cycle_passes.json -c river -d /mnt/data/swot -s /mnt/data/s3_list.json --hpc',\n",
    "    'priors_unconstrained': 'singularity run -c --bind '+ f'{mnt_dir}/input:/mnt/data,/tmp:/tmp --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'priors_unconstrained.sif')+' -i -235 -r unconstrained -p usgs gbpriors -l 0000 -g',\n",
    "    'priors_constrained': 'singularity run -c --bind '+ f'{mnt_dir}/input:/mnt/data,/tmp:/tmp --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'priors_constrained.sif')+' -i -235 -r constrained -p usgs gbpriors -l 0000 -g',\n",
    "    'prediagnostics':'singularity run --bind '+ f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/diagnostics/prediagnostics:/mnt/data/output --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'prediagnostics.sif'),\n",
    "    'sad':'singularity run --bind '+ f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/flpe/sad:/mnt/data/output --env '+ 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'sad.sif'),\n",
    "    'momma': 'singularity run --bind '+ f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/flpe/momma:/mnt/data/output  --env '+ 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'momma.sif'),\n",
    "    'metroman': 'singularity run --bind '+ f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/flpe/metroman:/mnt/data/output  --env '+ 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'metroman.sif'),\n",
    "    'h2ivdi': 'singularity run --bind '+ f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/flpe/hivdi:/mnt/data/output  --env '+ 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'h2ivdi.sif'),\n",
    "    'geobam': 'singularity run --bind '+ f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/flpe/geobam:/mnt/data/output  --env '+ 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'neobam.sif'),\n",
    "    'moi_unconstrained': 'singularity run --bind ' + f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/flpe:/mnt/data/flpe,{mnt_dir}/moi:/mnt/data/output --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'moi_unconstrained.sif') + ' basin.json -v unconstrained',\n",
    "    'moi_constrained': 'singularity run --bind ' + f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/flpe:/mnt/data/flpe,{mnt_dir}/moi:/mnt/data/output --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'moi_constrained.sif') + ' basin.json -v constrained',\n",
    "    'offline_unconstrained':'singularity run --bind ' + f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/moi:/mnt/data/moi,{mnt_dir}/offline:/mnt/data/output --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'offline.sif') + ' unconstrained timeseries integrator reaches.json',\n",
    "    'offline_constrained':'singularity run --bind ' + f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/moi:/mnt/data/moi,{mnt_dir}/offline:/mnt/data/output --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'offline.sif') + ' constrained timeseries integrator reaches.json',\n",
    "    'output_first_unconstrained': 'singularity run --bind ' + f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/flpe:/mnt/data/flpe,{mnt_dir}/moi:/mnt/data/moi,{mnt_dir}/diagnostics:/mnt/data/diagnostics,{mnt_dir}/offline:/mnt/data/offline,{mnt_dir}/validation:/mnt/data/validation,{mnt_dir}/output:/mnt/data/output --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'output_first_unconstrained.sif')  + ' -i -235 -r unconstrained -m input priors prediag momma hivdi neobam metroman sic4dvar sad moi offline swot',\n",
    "    'output_first_constrained': 'singularity run --bind ' + f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/flpe:/mnt/data/flpe,{mnt_dir}/moi:/mnt/data/moi,{mnt_dir}/diagnostics:/mnt/data/diagnostics,{mnt_dir}/offline:/mnt/data/offline,{mnt_dir}/validation:/mnt/data/validation,{mnt_dir}/output:/mnt/data/output --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'output_first_constrained.sif')  + ' -i -235 -r constrained -m input priors prediag momma hivdi neobam metroman sic4dvar sad moi offline swot',\n",
    "    'postd-flpe':'singularity run --bind '+ f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/flpe:/mnt/data/flpe,{mnt_dir}/diagnostics/postdiagnostics/reach:/mnt/data/output,{mnt_dir}/output/sos:/mnt/data/results --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'postd-flpe.sif') + ' 0.25 reaches.json LOCAL',\n",
    "    'postd-moi':'singularity run --bind '+ f'{mnt_dir}/moi:/mnt/data/moi,{mnt_dir}/flpe:/mnt/data/flpe,{mnt_dir}/input:/mnt/data/input,{mnt_dir}/flpe:/mnt/data/flpe,{mnt_dir}/diagnostics/postdiagnostics/basin:/mnt/data/output,{mnt_dir}/output/sos:/mnt/data/results --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'postd-moi.sif') + ' 0.25 reaches.json LOCAL',\n",
    "    'validation_unconstrained':'singularity run --bind ' + f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/offline:/mnt/data/offline,{mnt_dir}/validation:/mnt/data/output --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir,'validation.sif') + ' reaches.json unconstrained',\n",
    "    'validation_consrained':'singularity run --bind ' + f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/offline:/mnt/data/offline,{mnt_dir}/validation:/mnt/data/output --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir,'validation.sif') + ' reaches.json constrained',\n",
    "    'output_final_unconstrained': 'singularity run --bind ' + f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/flpe:/mnt/data/flpe,{mnt_dir}/moi:/mnt/data/moi,{mnt_dir}/diagnostics:/mnt/data/diagnostics,{mnt_dir}/offline:/mnt/data/offline,{mnt_dir}/validation:/mnt/data/validation,{mnt_dir}/output:/mnt/data/output --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'output_first_unconstrained.sif')  + ' -i -235 -r unconstrained -m input priors prediag momma hivdi neobam metroman sic4dvar sad moi offline postdiagnostics validation swot',\n",
    "    'output_final_constrained': 'singularity run --bind ' + f'{mnt_dir}/input:/mnt/data/input,{mnt_dir}/flpe:/mnt/data/flpe,{mnt_dir}/moi:/mnt/data/moi,{mnt_dir}/diagnostics:/mnt/data/diagnostics,{mnt_dir}/offline:/mnt/data/offline,{mnt_dir}/validation:/mnt/data/validation,{mnt_dir}/output:/mnt/data/output --env ' + 'AWS_BATCH_JOB_ARRAY_INDEX=${SLURM_ARRAY_TASK_ID} ' + os.path.join(sif_dir, 'output_first_constrained.sif')  + ' -i -235 -r constrained -m input priors prediag momma hivdi neobam metroman sic4dvar sad moi offline postdiagnostics validation swot',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_to_run = 'output_final_unconstrained'\n",
    "\n",
    "node_details = {\n",
    "    'cores' :48,\n",
    "    'ram' : 128\n",
    "}\n",
    "\n",
    "job_details = {\n",
    "    'partition': partition,\n",
    "    'number_things_to_process':6,\n",
    "    'nodes':1,\n",
    "    'cores':8,\n",
    "    'ram':12,\n",
    "    'time': '10:00:00',\n",
    "    'name': 'cfl_output',\n",
    "    'run_command': command_dict[module_to_run],\n",
    "    'module_name': module_to_run\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.666666666666666 6.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def construct_sh_dict(node_details, job_details):\n",
    "\n",
    "    ram_limited = False\n",
    "    cpu_limited = False\n",
    "\n",
    "    sh_dict = {\n",
    "        'partition': job_details['partition'],\n",
    "        'nodes': job_details['nodes'],\n",
    "        'ntasks-per-node':1,\n",
    "        'cpus-per-task':job_details['cores'],\n",
    "        'mem':str(job_details['ram'])+'G',\n",
    "        'time': job_details['time'],\n",
    "        'job-name': job_details['name'],\n",
    "        'array': '0-' + str(job_details['number_things_to_process']),\n",
    "        'run_command': job_details['run_command']\n",
    "\n",
    "    }\n",
    "\n",
    "    resources_available = {\n",
    "        'cores': node_details['cores'] * job_details['nodes'],\n",
    "        'ram': node_details['ram'] * job_details['nodes']\n",
    "    }\n",
    "\n",
    "    ram_constraint = resources_available['ram']/job_details['ram']\n",
    "    cpu_constraint = resources_available['cores']/job_details['cores']\n",
    "    print(ram_constraint, cpu_constraint)\n",
    "\n",
    "    if ram_constraint > cpu_constraint:\n",
    "        cpu_limited = True\n",
    "\n",
    "    else:\n",
    "        ram_limited = True\n",
    "\n",
    "    if cpu_limited:\n",
    "        array_mod = cpu_constraint\n",
    "    \n",
    "    if ram_limited:\n",
    "        array_mod = ram_constraint\n",
    "\n",
    "    if array_mod < job_details['number_things_to_process']:\n",
    "        sh_dict['array'] += f'%{str(int(array_mod))}'\n",
    "\n",
    "    return sh_dict\n",
    "\n",
    "def create_slurm_script(node_details=node_details, job_details=job_details, build_image=False, sif_dir='foo', singularity_version = '3.7.0'):\n",
    "    if build_image:\n",
    "        module_name = job_details['module_name']\n",
    "        sp.run(['singularity', 'build', '-F',os.path.join(sif_dir,module_name + '.sif'), f'docker://travissimmons/{module_name.split(\"_\")[0]}'])\n",
    "        \n",
    "\n",
    "\n",
    "    sh_dict = construct_sh_dict(node_details=node_details, job_details=job_details)\n",
    "    file = open('items.sh','w')\n",
    "    file.write('#!/bin/bash \\n')\n",
    "    file.write(f'#SBATCH -o {os.path.join(report_dir, \"output.%a.out\")}' + ' \\n')\n",
    "\n",
    "    for item in sh_dict:\n",
    "        if item != 'run_command':\n",
    "            file.write(f'#SBATCH --{item}={sh_dict[item]} \\n')\n",
    "        else:\n",
    "            file.write(f'\\nmodule load singularity/{singularity_version}\\n')\n",
    "            file.write(f'{sh_dict[item]}')\n",
    "    file.close()\n",
    "\n",
    "\n",
    "create_slurm_script(node_details=node_details, job_details=job_details, build_image= False, sif_dir = sif_dir, singularity_version=singularity_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
